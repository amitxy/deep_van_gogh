{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Preprocessing The Data",
   "id": "21d5455a7d46d076"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "In order to have smooth and efficient learning procedure we will do some preprocessing on the data",
   "id": "4d47659043c41bf"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The data is a subset of Post_impressionism folder from <a href=\"https://www.kaggle.com/datasets/steubk/wikiart\">WIKIART</a> collection. <br> You can find the dataset and the csv file at: <a href=\"https://drive.google.com/drive/folders/1vDTerxVX999kI7wkZHvx4xNGUn5bdPVY?usp=sharing\">HERE</a>",
   "id": "6104240654fe27d2"
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-29T13:14:55.969693Z",
     "start_time": "2025-03-29T13:14:55.947693Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, Subset\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import utils # Project utilities\n",
    "import importlib\n",
    "importlib.reload(utils)\n"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils' from 'C:\\\\Projects\\\\deep_van_gogh\\\\utils.py'>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-29T13:14:59.318813Z",
     "start_time": "2025-03-29T13:14:59.278817Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Our csv file\n",
    "classes = pd.read_csv(utils.CSV_PATH)\n",
    "classes.head()"
   ],
   "id": "b88f0304c5690700",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                            filename            artist  \\\n",
       "0  Post_Impressionism/edouard-cortes_the-theater-...    edouard cortes   \n",
       "1  Post_Impressionism/edouard-cortes_theatre-du-c...    edouard cortes   \n",
       "2  Post_Impressionism/edouard-vuillard_boulevard-...  edouard vuillard   \n",
       "3  Post_Impressionism/edouard-vuillard_figures-ea...  edouard vuillard   \n",
       "4  Post_Impressionism/edouard-vuillard_sacha-guit...  edouard vuillard   \n",
       "\n",
       "                    genre                              description  \\\n",
       "0  ['Post Impressionism']     the-theater-of-the-comedie-francaise   \n",
       "1  ['Post Impressionism']                    theatre-du-chatelet-1   \n",
       "2  ['Post Impressionism']                boulevard-of-battignolles   \n",
       "3  ['Post Impressionism']  figures-eating-in-a-garden-by-the-water   \n",
       "4  ['Post Impressionism']   sacha-guitry-in-his-dressing-room-1912   \n",
       "\n",
       "              phash  width  height  genre_count subset  is_van_gogh  \n",
       "0  9491ada9caf05cf1   1675    1382            1  train            0  \n",
       "1  c7d69030996f36e4   1896    1382            1  train            0  \n",
       "2  eb7214d866c638b5   1688    1382            1  train            0  \n",
       "3  d3272568d0a95e3d   1684    1382            1  train            0  \n",
       "4  dae0254af31a6fa4   1818    1382            1  train            0  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>artist</th>\n",
       "      <th>genre</th>\n",
       "      <th>description</th>\n",
       "      <th>phash</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>genre_count</th>\n",
       "      <th>subset</th>\n",
       "      <th>is_van_gogh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Post_Impressionism/edouard-cortes_the-theater-...</td>\n",
       "      <td>edouard cortes</td>\n",
       "      <td>['Post Impressionism']</td>\n",
       "      <td>the-theater-of-the-comedie-francaise</td>\n",
       "      <td>9491ada9caf05cf1</td>\n",
       "      <td>1675</td>\n",
       "      <td>1382</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Post_Impressionism/edouard-cortes_theatre-du-c...</td>\n",
       "      <td>edouard cortes</td>\n",
       "      <td>['Post Impressionism']</td>\n",
       "      <td>theatre-du-chatelet-1</td>\n",
       "      <td>c7d69030996f36e4</td>\n",
       "      <td>1896</td>\n",
       "      <td>1382</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Post_Impressionism/edouard-vuillard_boulevard-...</td>\n",
       "      <td>edouard vuillard</td>\n",
       "      <td>['Post Impressionism']</td>\n",
       "      <td>boulevard-of-battignolles</td>\n",
       "      <td>eb7214d866c638b5</td>\n",
       "      <td>1688</td>\n",
       "      <td>1382</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Post_Impressionism/edouard-vuillard_figures-ea...</td>\n",
       "      <td>edouard vuillard</td>\n",
       "      <td>['Post Impressionism']</td>\n",
       "      <td>figures-eating-in-a-garden-by-the-water</td>\n",
       "      <td>d3272568d0a95e3d</td>\n",
       "      <td>1684</td>\n",
       "      <td>1382</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Post_Impressionism/edouard-vuillard_sacha-guit...</td>\n",
       "      <td>edouard vuillard</td>\n",
       "      <td>['Post Impressionism']</td>\n",
       "      <td>sacha-guitry-in-his-dressing-room-1912</td>\n",
       "      <td>dae0254af31a6fa4</td>\n",
       "      <td>1818</td>\n",
       "      <td>1382</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We want to make sure that all the images in our dataset are labeled in the csv file:",
   "id": "925ec4014a91fe8c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T15:50:18.443137Z",
     "start_time": "2025-01-14T15:50:18.072697Z"
    }
   },
   "cell_type": "code",
   "source": [
    "prefix = 'Post_Impressionism/'\n",
    "filenames = classes['filename'].values\n",
    "files_not_in_csv = []\n",
    "for filename in os.listdir(utils.DATASET_DIR):\n",
    "        path = prefix + filename\n",
    "        if path not in filenames:\n",
    "            files_not_in_csv.append(filename)\n",
    "print(f'We have {len(files_not_in_csv)} files that are not present in the dataset.')"
   ],
   "id": "47bf1b703ab8fab3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 120 files that are not present in the dataset.\n"
     ]
    }
   ],
   "execution_count": 55
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "It seems that we have 120 missing labels, so because that we have a large dataset, and we only focus on Van gogh paintings, we'll delete those images",
   "id": "7e9d505888d3bc6e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T15:50:57.023636Z",
     "start_time": "2025-01-14T15:50:56.557688Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for filename in files_not_in_csv:\n",
    "    os.remove(os.path.join(utils.DATASET_DIR, filename))\n",
    "print('Successfully removed files from the dataset.')"
   ],
   "id": "e54ab1ed318cd2f1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully removed files from the dataset.\n"
     ]
    }
   ],
   "execution_count": 57
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now we need to implement a convenient way to access our data, so we created a class that handles the data loading for us:",
   "id": "a399c55e654336b9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-29T12:05:24.208451Z",
     "start_time": "2025-03-29T12:05:24.195449Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def map_labels(root, target):\n",
    "    \"\"\"Reads a CSV file named 'classes.csv' from the specified root directory and creates a mapping\n",
    "    of file paths (with backslashes replaced) to labels based on a specified target column.\n",
    "\n",
    "    :param root:\n",
    "        The root directory containing the 'classes.csv' file. The directory should\n",
    "        include the dataset used for generating the label mapping.\n",
    "        The path should be compatible with filesystem conventions.\n",
    "\n",
    "    :param target:\n",
    "        The column name in 'classes.csv' to be used for creating the mapping. This\n",
    "        column must exist in the CSV file and represents the labels assigned to the\n",
    "        file names.\n",
    "\n",
    "    :return:\n",
    "        A dictionary where keys are file paths with updated backslashes, and values\n",
    "        are label values extracted from the specified column in the 'classes.csv' file.\n",
    "    \"\"\"\n",
    "    classes_df = pd.read_csv(os.path.join(root, 'classes.csv'))  # Read CSV file\n",
    "    add_backslash= lambda s: s.replace('/','\\\\')\n",
    "    label_mapping = { f\"{root}\\\\{add_backslash(row['filename'])}\": row[target] for _, row in classes_df.iterrows()}  # Map image names to labels\n",
    "    return label_mapping\n",
    "class ImageFolderForBinaryClassification(ImageFolder):\n",
    "    \"\"\"\n",
    "    Extends the ImageFolder class to support binary classification with custom label mapping.\n",
    "\n",
    "    This class is designed to preprocess and organize a dataset for binary classification tasks.\n",
    "    It overrides the default behavior of ImageFolder to allow specification of a target category\n",
    "    and the corresponding binary labels for dataset samples.\n",
    "\n",
    "    :ivar target: The target class label for binary classification.\n",
    "    :type target: str\n",
    "    :ivar transform: Transformation to be applied on images, such as resizing, normalization, etc.\n",
    "    :type transform: Callable or None\n",
    "    :ivar samples: List of (path, label) tuples where label reflects binary classification labels.\n",
    "    :type samples: list\n",
    "    \"\"\"\n",
    "    def __init__(self, root, target, transform=None,):\n",
    "        super().__init__(root, transform=transform)\n",
    "        self.target = target\n",
    "        label_mapping = map_labels(root, target)\n",
    "        self.__pre_process_data(label_mapping) # Apply pre precessing\n",
    "\n",
    "    def __pre_process_data(self, label_mapping):\n",
    "        \"\"\"\n",
    "        Pre-processes the data by updating the labels of the sample dataset based on the given\n",
    "        label mapping dictionary. If a path is not found in the dictionary, a default label of -1 is used.\n",
    "\n",
    "        :param label_mapping: A dictionary where keys are sample paths and values are corresponding\n",
    "                              labels to be assigned.\n",
    "        :type label_mapping: dict\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        for i in range(len(self.samples)):\n",
    "            path, _ = self.samples[i]\n",
    "            label = label_mapping.get(path, -1) # Return -1 if no path was found\n",
    "            self.samples[i] = (path, label)\n",
    "\n",
    "    # probably redundant\n",
    "    def get_subset_by_indices(self, indices):\n",
    "        \"\"\"\n",
    "        Returns a subset of the dataset using the specified indices.\n",
    "        \"\"\"\n",
    "        subset = ImageFolderForBinaryClassification(self.root, self.target, transform=self.transform)\n",
    "        subset.samples = [subset.samples[i] for i in indices ]\n",
    "        return subset"
   ],
   "id": "34b9ef52e0a8a1e6",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Creating our dataset loader\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(), # Convert the image to a PyTorch tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229,0.224, 0.225])]) # Normalize the pixel values based on ImageNet statistics\n",
    "\n",
    "dataset = ImageFolderForBinaryClassification(root=utils.DATA_DIR, target='is_van_gogh', transform=transform)"
   ],
   "id": "d58560c3c0c72f36",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "After working with our loader we noticed that it takes a lot of time to load the picture, let's see how much time a full epoch over the dataset takes:",
   "id": "f1ae8d2601d3a489"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-20T11:12:28.546254Z",
     "start_time": "2025-01-20T11:08:22.812022Z"
    }
   },
   "cell_type": "code",
   "source": [
    "start_time = time.time()\n",
    "for sample in dataset:\n",
    "    pass\n",
    "print(f'Epoch time: {(time.time() - start_time)/60:.1f} minutes')"
   ],
   "id": "984b25282883e2c8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch time: 4.1 minutes\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "It takes 4 minutes to perform a pass over the dataset, as a result we decided to optimize our dataset by converting the transformed images into numpy format:",
   "id": "bb71e4093e477a0d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-29T13:33:10.243252Z",
     "start_time": "2025-03-29T13:33:10.221237Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def optimize_dataset(dataset, output_name):\n",
    "    \"\"\"\n",
    "    Optimize and convert a given dataset into a compressed NumPy file format. This function processes\n",
    "    the dataset by converting its elements (images and labels) into NumPy arrays, and then saves them\n",
    "    in a `.npz` compressed file for efficient storage and further use.\n",
    "\n",
    "    :param dataset: The input dataset containing image data and their corresponding labels. Images\n",
    "        are expected to be in Tensor format, while labels can be in any format compatible with NumPy.\n",
    "    :type dataset: Iterable\n",
    "\n",
    "    :param output_name: The name of the output file, excluding the file extension, in which the\n",
    "        optimized dataset will be saved. The file will be saved in the directory defined by\n",
    "        `utils.OPTIMIZED_DIR` with the file extension `.npz`.\n",
    "    :type output_name: str\n",
    "\n",
    "    :return: The function does not return any value. The optimized dataset is saved directly to a\n",
    "        compressed `.npz` file in the specified output directory.\n",
    "    :rtype: None\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    labels = []\n",
    "    n = len(dataset)\n",
    "    print(f\"Converting {n} images into NumPy format...\")\n",
    "    for i, (data, label) in enumerate(dataset):\n",
    "        utils.show_optimization_progress(i + 1, n)\n",
    "        images.append(data.numpy())  # Convert Tensor to NumPy\n",
    "        labels.append(label)\n",
    "    path = f\"{utils.OPTIMIZED_DIR}/{output_name}.npz\"\n",
    "    np.savez_compressed(path, images=np.array(images), labels=np.array(labels))\n",
    "    print(f\"Saved dataset to {path}\")\n",
    "\n",
    "# optimize_dataset(dataset, 'dataset')"
   ],
   "id": "df9befd8e34cddf7",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Then we created a class to decode our data back from numpy format into torch tensor object:",
   "id": "49285b649282af90"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-20T14:18:17.735446Z",
     "start_time": "2025-01-20T14:18:00.702531Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class NumPyDataset(Dataset):\n",
    "    def __init__(self, file_path):\n",
    "        data = np.load(file_path)\n",
    "        self.images = data[\"images\"]\n",
    "        self.labels = data[\"labels\"]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = torch.tensor(self.images[idx], dtype=torch.float32)\n",
    "        y = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        return x, y\n",
    "\n",
    "# Loading our optimized dataset into memory\n",
    "optimized_dataset = NumPyDataset(utils.OPTIMIZED_DIR + '/dataset.npz')"
   ],
   "id": "1fcf46a58d8e042d",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Let's see how much it improved our performance:",
   "id": "e1efb1331a3b6d50"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-20T14:18:19.637447Z",
     "start_time": "2025-01-20T14:18:19.100446Z"
    }
   },
   "cell_type": "code",
   "source": [
    "start_time = time.time()\n",
    "for sample in optimized_dataset:\n",
    "    pass\n",
    "print(f'Epoch time: {time.time() - start_time:.1f} seconds')"
   ],
   "id": "2829907536d80a9b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch time: 0.5 seconds\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "It took us 0.5 SECONDS! to preform a complete pass over the entire dataset, comparing to the previous way which took us 4 minutes = 240 seconds we get our optimized dataset is roughly  240/0.5 = 480 times faster.",
   "id": "88057cd7621cdd3d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now we will optimize our data augmentations:",
   "id": "1713ba17824646d7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T08:47:40.462748Z",
     "start_time": "2025-01-21T08:47:40.429925Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def transform_wrapper(composed_transform: transforms.Compose):\n",
    "    \"\"\"\n",
    "    Applies a specified transformation sequence to an input while ensuring ImageNet\n",
    "    standard preprocessing steps are integrated.\n",
    "    :param composed_transform: A composite transformation object containing a list\n",
    "        of transformations to be applied sequentially.\n",
    "    :type composed_transform: transforms.Compose\n",
    "    :return: A new composite transformation object with ImageNet preprocessing\n",
    "        steps integrated.\n",
    "    :rtype: transforms.Compose\n",
    "    \"\"\"\n",
    "    img_net_transform = transforms.Compose([\n",
    "        transforms.ToTensor(), # Convert the image to a PyTorch tensor\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229,0.224, 0.225])]) # Normalize the pixel values based on ImageNet statistics\n",
    "\n",
    "    # Check if transforms.ToTensor() was already applied\n",
    "    if any(map(lambda t: isinstance(t, transforms.ToTensor), composed_transform.transforms)):\n",
    "        return transforms.Compose([*composed_transform.transforms, *img_net_transform.transforms[1:]])\n",
    "\n",
    "    return transforms.Compose([*composed_transform.transforms, *img_net_transform.transforms])"
   ],
   "id": "42295243ba3f6441",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-29T13:27:16.432965Z",
     "start_time": "2025-03-29T13:27:16.329968Z"
    }
   },
   "cell_type": "code",
   "source": [
    "flip_transform = transforms.Compose([\n",
    "    transforms.RandomVerticalFlip(p=0.5),\n",
    "    transforms.RandomRotation(degrees=30),\n",
    "    transforms.RandomPerspective(distortion_scale=0.3, p=0.5),\n",
    "])\n",
    "dataset_to_optimize = ImageFolderForBinaryClassification(root=utils.DATA_DIR, target='is_van_gogh', transform=transform_wrapper(flip_transform))\n",
    "optimize_dataset(dataset_to_optimize, 'flip')"
   ],
   "id": "7699c7769f6f1169",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-29T13:27:19.073013Z",
     "start_time": "2025-03-29T13:27:19.048013Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dropout_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    *([transforms.RandomErasing(p=0.5, scale=(0.01, 0.01), ratio=(1, 1))]*25),\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "])\n",
    "dataset_to_optimize = ImageFolderForBinaryClassification(root=utils.DATA_DIR, target='is_van_gogh', transform=transform_wrapper(dropout_transform))\n",
    "optimize_dataset(dataset_to_optimize, 'dropout')"
   ],
   "id": "606d2f441e631e24",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-29T13:27:22.051149Z",
     "start_time": "2025-03-29T13:27:22.023152Z"
    }
   },
   "cell_type": "code",
   "source": [
    "affine_transform = transforms.Compose([\n",
    "    transforms.RandomAffine(degrees=180, translate=(0.1, 0.1), scale=(0.8, 1.2), shear=(10,10)),\n",
    "    transforms.RandomEqualize(p=0.5),\n",
    "])\n",
    "dataset_to_optimize = ImageFolderForBinaryClassification(root=utils.DATA_DIR, target='is_van_gogh', transform=transform_wrapper(affine_transform))\n",
    "optimize_dataset(dataset_to_optimize, 'affine')"
   ],
   "id": "1444aee240e6ce74",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-29T13:27:25.274574Z",
     "start_time": "2025-03-29T13:27:25.261572Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 30,
   "source": [
    "blur_transform = transforms.Compose([\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.GaussianBlur(kernel_size=(3,3), sigma=(0.1, 2))\n",
    "])\n",
    "dataset_to_optimize = ImageFolderForBinaryClassification(root=utils.DATA_DIR, target='is_van_gogh', transform=transform_wrapper(blur_transform))\n",
    "optimize_dataset(dataset_to_optimize, 'blur')"
   ],
   "id": "f446472bcb695db"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The total size of the optimized files was around 8.5 GB, so we decided to optimize the augmentations for only a subset of the train_dataset.<br>\n",
    "To be exact, we took  731 samples from the train dataset and preformed 4 augmentations on them, so we will have an additional 4 datasets of 731 samples each. <br>"
   ],
   "id": "e3922290f4ee6349"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-29T13:37:04.726279Z",
     "start_time": "2025-03-29T13:34:25.610131Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_rows = classes[classes['subset'] == 'train']\n",
    "train_indices, val_indices = train_test_split(train_rows.index.to_list(), test_size=0.2, random_state=utils.SEED, stratify=train_rows['is_van_gogh'])\n",
    "\n",
    "train_subset = train_rows.iloc[train_indices]\n",
    "train_subset_idx, _ = train_test_split(train_subset.index.to_list(), test_size=0.75, random_state=utils.SEED, stratify=train_subset['is_van_gogh'])\n",
    "\n",
    "for dset_name in ['flip', 'dropout', 'affine', 'blur']:\n",
    "    print(f'Loading {dset_name} dataset')\n",
    "    dset = utils.get_opt_dataset(dset_name, train_subset_idx)\n",
    "    print('Optimizing dataset:', dset_name)\n",
    "    optimize_dataset(dset, f'{dset_name}')\n",
    "\n"
   ],
   "id": "ee0665237446a56a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading flip dataset\n",
      "Optimizing dataset: flip\n",
      "Converting 731 images into NumPy format...\n",
      "Optimizing dataset... 100.00%\n",
      "Saved dataset to data/optimized//flip_lite.npz\n",
      "Loading dropout dataset\n",
      "Optimizing dataset: dropout\n",
      "Converting 731 images into NumPy format...\n",
      "Optimizing dataset... 100.00%\n",
      "Saved dataset to data/optimized//dropout_lite.npz\n",
      "Loading affine dataset\n",
      "Optimizing dataset: affine\n",
      "Converting 731 images into NumPy format...\n",
      "Optimizing dataset... 100.00%\n",
      "Saved dataset to data/optimized//affine_lite.npz\n",
      "Loading blur dataset\n",
      "Optimizing dataset: blur\n",
      "Converting 731 images into NumPy format...\n",
      "Optimizing dataset... 100.00%\n",
      "Saved dataset to data/optimized//blur_lite.npz\n"
     ]
    }
   ],
   "execution_count": 35
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
