{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T17:27:04.347432Z",
     "start_time": "2025-01-22T17:26:56.695449Z"
    }
   },
   "source": [
    "import os\n",
    "import random\n",
    "from platform import architecture\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision import transforms, models\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "from sklearn.model_selection import KFold\n",
    "from collections import defaultdict\n",
    "from optuna import trial\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, Subset, ConcatDataset\n",
    "import optuna\n",
    "import wandb\n",
    "# Project utilities\n",
    "import utils\n",
    "from train import train_model_with_hyperparams\n",
    "\n",
    "VGG19 = 'VGG19'\n",
    "ALEXNET = 'AlexNet'\n",
    "\n",
    "# Set seed\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "# torch.backends.cudnn.deterministic = True\n",
    "# torch.use_deterministic_algorithms = True"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T17:27:04.394061Z",
     "start_time": "2025-01-22T17:27:04.353432Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Check if you're working locally or not\n",
    "if not (os.path.exists(utils.CSV_PATH) and os.path.exists(utils.OPTIMIZED_DIR)):\n",
    "    print(f\"[!] You are NOT on the project's directory [!]\\n\"\n",
    "          f\"Please run the following command (in either CMD or anaconda prompt): \\n\"\n",
    "          f\"jupyter notebook --notebook-dir PROJECT_DIR\\n\"\n",
    "          r\"Where PROJECT_DIR is the project's directory in your computer e.g: C:\\Users\\amitr5\\PycharmProjects\\deep_van_gogh\")"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Loading our data\n",
    "We will load the optimized datasets from our custom dataset object\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T17:27:13.063121Z",
     "start_time": "2025-01-22T17:27:04.490630Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class NumPyDataset(Dataset):\n",
    "    def __init__(self, file_path):\n",
    "        data = np.load(file_path)\n",
    "        self.images = data[\"images\"]\n",
    "        self.labels = data[\"labels\"]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = torch.tensor(self.images[idx], dtype=torch.float32)\n",
    "        y = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        return x, y\n",
    "\n",
    "dataset = NumPyDataset(os.path.join(utils.OPTIMIZED_DIR, 'dataset.npz'))"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "You can find the optimized dataset files <a href=\"https://drive.google.com/drive/folders/1TBlNcRsRHJ7_rxh_h7_yn_-Ak66Uj_mp?usp=sharing\">HERE</a><br/>\n",
    "Loading the train and test datasets:"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T17:27:13.110187Z",
     "start_time": "2025-01-22T17:27:13.081667Z"
    }
   },
   "cell_type": "code",
   "source": [
    "classes = pd.read_csv(utils.CSV_PATH)\n",
    "train_indices, val_indices = train_test_split(classes[classes['subset'] == 'train'].index.tolist(), test_size=0.2, random_state=SEED)\n",
    "train_dataset = Subset(dataset, train_indices)\n",
    "val_dataset = Subset(dataset, val_indices)\n",
    "test_dataset = Subset(dataset, classes[classes['subset'] == 'test'].index.tolist())"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Data Augmentation"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T12:07:16.417404Z",
     "start_time": "2025-01-14T12:07:16.030262Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# torch.manual_seed(SEED)\n",
    "# n_times = 25\n",
    "# dropout_transform = transforms.Compose([\n",
    "#     transforms.Resize((224, 224)),\n",
    "#     transforms.ToTensor(),\n",
    "#     *([transforms.RandomErasing(p=0.5, scale=(0.01, 0.01), ratio=(1, 1))]*n_times),\n",
    "#     transforms.Grayscale(num_output_channels=3),\n",
    "#     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229,0.224, 0.225])\n",
    "# ])\n",
    "# dropout_dataset = Subset(preprocessing.ImageFolderForBinaryClassification(root=ROOT, transform=dropout_transform, target='is_van_gogh'), train_indices)\n",
    "# augmented_train_dataset = ConcatDataset([dropout_dataset, train_dataset])\n",
    "# augmented_train_dataset = train_dataset\n",
    "# train_loader = DataLoader(augmented_train_dataset, batch_size=128, shuffle=True, num_workers=4, pin_memory=True, prefetch_factor=8)\n",
    "# val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False, num_workers=4)"
   ],
   "outputs": [],
   "execution_count": 38
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jFD4XwIchub9"
   },
   "source": [
    "# Fine tuning VGG19"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T17:46:54.673658Z",
     "start_time": "2025-01-22T17:46:54.660660Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class FinedTunedModel(nn.Module):\n",
    "    def __init__(self, base_model, architecture:str):\n",
    "        super(FinedTunedModel, self).__init__()\n",
    "        self._architecture = architecture  # Save the base model architecture\n",
    "        base_children_list = list(base_model.children())\n",
    "        self.features_extractor = nn.Sequential(*base_children_list[:-1]).to(device)\n",
    "        for param in self.features_extractor.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        # Modify the classifier to fit to our problem (2 classes)\n",
    "        self.classifier = nn.Sequential(*base_children_list[-1])\n",
    "        self.classifier[-1] = nn.Linear(4096, 2).to(device)  # Replaces the final layer of the base model's classifier with a new fully connected layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        base_model_output = self.features_extractor(x)\n",
    "        return self.classifier(torch.flatten(base_model_output, start_dim=1))\n",
    "    @property\n",
    "    def architecture(self):\n",
    "        return self._architecture\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T17:46:57.178508Z",
     "start_time": "2025-01-22T17:46:55.255789Z"
    }
   },
   "cell_type": "code",
   "source": [
    "vgg19 = models.vgg19(weights=models.VGG19_Weights.DEFAULT).to(device) # Load pre-trained VGG19 model\n",
    "vgg_model = FinedTunedModel(vgg19, VGG19).to(device)\n",
    "vgg_model"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FinedTunedModel(\n",
       "  (features_extractor): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (6): ReLU(inplace=True)\n",
       "      (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (8): ReLU(inplace=True)\n",
       "      (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (11): ReLU(inplace=True)\n",
       "      (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (13): ReLU(inplace=True)\n",
       "      (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (15): ReLU(inplace=True)\n",
       "      (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (17): ReLU(inplace=True)\n",
       "      (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (20): ReLU(inplace=True)\n",
       "      (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (22): ReLU(inplace=True)\n",
       "      (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (24): ReLU(inplace=True)\n",
       "      (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (26): ReLU(inplace=True)\n",
       "      (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (29): ReLU(inplace=True)\n",
       "      (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (31): ReLU(inplace=True)\n",
       "      (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (33): ReLU(inplace=True)\n",
       "      (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (35): ReLU(inplace=True)\n",
       "      (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (1): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T14:51:23.954322Z",
     "start_time": "2025-01-22T14:42:44.998045Z"
    }
   },
   "source": [
    "# Optuna for our vgg model with the default config\n",
    "study = optuna.create_study(study_name=VGG19, direction='minimize')\n",
    "study.optimize(lambda trial: objective(trial, vgg_model, config={}), n_trials=3)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-22 16:42:45,007] A new study created in memory with name: VGG19\n",
      "wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "wandb: Currently logged in as: amitr5 (amitr5-tel-aviv-university). Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.19.1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>C:\\Projects\\deep_van_gogh\\wandb\\run-20250122_164246-alraug5q</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/amitr5-tel-aviv-university/deep_van_gogh/runs/alraug5q' target=\"_blank\">VGG19_trial_0</a></strong> to <a href='https://wandb.ai/amitr5-tel-aviv-university/deep_van_gogh' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/amitr5-tel-aviv-university/deep_van_gogh' target=\"_blank\">https://wandb.ai/amitr5-tel-aviv-university/deep_van_gogh</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/amitr5-tel-aviv-university/deep_van_gogh/runs/alraug5q' target=\"_blank\">https://wandb.ai/amitr5-tel-aviv-university/deep_van_gogh/runs/alraug5q</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▃▅▆█</td></tr><tr><td>Train Accuracy</td><td>▁▅▆▇█</td></tr><tr><td>Train Loss</td><td>█▄▃▂▁</td></tr><tr><td>Validation Accuracy</td><td>▁▃▄█▇</td></tr><tr><td>Validation Loss</td><td>█▄▃▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>5</td></tr><tr><td>Train Accuracy</td><td>0.96272</td></tr><tr><td>Train Loss</td><td>0.0829</td></tr><tr><td>Validation Accuracy</td><td>0.95349</td></tr><tr><td>Validation Loss</td><td>0.14031</td></tr></table><br/></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">VGG19_trial_0</strong> at: <a href='https://wandb.ai/amitr5-tel-aviv-university/deep_van_gogh/runs/alraug5q' target=\"_blank\">https://wandb.ai/amitr5-tel-aviv-university/deep_van_gogh/runs/alraug5q</a><br> View project at: <a href='https://wandb.ai/amitr5-tel-aviv-university/deep_van_gogh' target=\"_blank\">https://wandb.ai/amitr5-tel-aviv-university/deep_van_gogh</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250122_164246-alraug5q\\logs</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-22 16:45:28,355] Trial 0 finished with value: 0.14031435123220515 and parameters: {'learning_rate': 1.758543662708524e-05, 'weight_decay': 2.997062748911493e-05, 'batch_size': 128}. Best is trial 0 with value: 0.14031435123220515.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.19.1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>C:\\Projects\\deep_van_gogh\\wandb\\run-20250122_164529-b7bho3pb</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/amitr5-tel-aviv-university/deep_van_gogh/runs/b7bho3pb' target=\"_blank\">VGG19_trial_1</a></strong> to <a href='https://wandb.ai/amitr5-tel-aviv-university/deep_van_gogh' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/amitr5-tel-aviv-university/deep_van_gogh' target=\"_blank\">https://wandb.ai/amitr5-tel-aviv-university/deep_van_gogh</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/amitr5-tel-aviv-university/deep_van_gogh/runs/b7bho3pb' target=\"_blank\">https://wandb.ai/amitr5-tel-aviv-university/deep_van_gogh/runs/b7bho3pb</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▃▅▆█</td></tr><tr><td>Train Accuracy</td><td>▁▆███</td></tr><tr><td>Train Loss</td><td>█▃▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▅▁█▁▄</td></tr><tr><td>Validation Loss</td><td>▁▄▅▆█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>5</td></tr><tr><td>Train Accuracy</td><td>0.99829</td></tr><tr><td>Train Loss</td><td>0.00642</td></tr><tr><td>Validation Accuracy</td><td>0.96033</td></tr><tr><td>Validation Loss</td><td>0.40956</td></tr></table><br/></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">VGG19_trial_1</strong> at: <a href='https://wandb.ai/amitr5-tel-aviv-university/deep_van_gogh/runs/b7bho3pb' target=\"_blank\">https://wandb.ai/amitr5-tel-aviv-university/deep_van_gogh/runs/b7bho3pb</a><br> View project at: <a href='https://wandb.ai/amitr5-tel-aviv-university/deep_van_gogh' target=\"_blank\">https://wandb.ai/amitr5-tel-aviv-university/deep_van_gogh</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250122_164529-b7bho3pb\\logs</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-22 16:48:04,051] Trial 1 finished with value: 0.14069072449663922 and parameters: {'learning_rate': 0.00021040501369206028, 'weight_decay': 8.022270892118722e-05, 'batch_size': 64}. Best is trial 0 with value: 0.14031435123220515.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.19.1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>C:\\Projects\\deep_van_gogh\\wandb\\run-20250122_164804-s6vgmphx</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/amitr5-tel-aviv-university/deep_van_gogh/runs/s6vgmphx' target=\"_blank\">VGG19_trial_2</a></strong> to <a href='https://wandb.ai/amitr5-tel-aviv-university/deep_van_gogh' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/amitr5-tel-aviv-university/deep_van_gogh' target=\"_blank\">https://wandb.ai/amitr5-tel-aviv-university/deep_van_gogh</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/amitr5-tel-aviv-university/deep_van_gogh/runs/s6vgmphx' target=\"_blank\">https://wandb.ai/amitr5-tel-aviv-university/deep_van_gogh/runs/s6vgmphx</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▃▅▆█</td></tr><tr><td>Train Accuracy</td><td>▁▇██▇</td></tr><tr><td>Train Loss</td><td>█▁▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▁▇▇█</td></tr><tr><td>Validation Loss</td><td>▁▁▃▅█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>5</td></tr><tr><td>Train Accuracy</td><td>0.98871</td></tr><tr><td>Train Loss</td><td>0.05793</td></tr><tr><td>Validation Accuracy</td><td>0.96443</td></tr><tr><td>Validation Loss</td><td>0.54825</td></tr></table><br/></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">VGG19_trial_2</strong> at: <a href='https://wandb.ai/amitr5-tel-aviv-university/deep_van_gogh/runs/s6vgmphx' target=\"_blank\">https://wandb.ai/amitr5-tel-aviv-university/deep_van_gogh/runs/s6vgmphx</a><br> View project at: <a href='https://wandb.ai/amitr5-tel-aviv-university/deep_van_gogh' target=\"_blank\">https://wandb.ai/amitr5-tel-aviv-university/deep_van_gogh</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250122_164804-s6vgmphx\\logs</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-22 16:51:23,773] Trial 2 finished with value: 0.2567416431067312 and parameters: {'learning_rate': 0.0007730411632807764, 'weight_decay': 1.4028971950181714e-06, 'batch_size': 80}. Best is trial 0 with value: 0.14031435123220515.\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T14:40:24.627744Z",
     "start_time": "2025-01-22T14:40:24.599729Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 14,
   "source": [
    "# Optuna objective function\n",
    "def objective(trial, model, config: dict) -> float:\n",
    "    \"\"\"\n",
    "    Generic Optuna objective function.\n",
    "    :param trial: Optuna trial object.\n",
    "    :param model: The neural network model to train\n",
    "    :param config: A dictionary with configurable values such as learning rate ranges, batch size ranges, etc.\n",
    "    :return:  best_val_loss: The best validation loss achieved during training.\n",
    "    \"\"\"\n",
    "    # Hyperparameter suggestions based on config\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\",\n",
    "                                        config.get(\"lr_min\", 1e-5),\n",
    "                                        config.get(\"lr_max\", 1e-3),\n",
    "                                        log=True)\n",
    "    weight_decay = trial.suggest_float(\"weight_decay\",\n",
    "                                       config.get(\"wd_min\", 1e-6),\n",
    "                                       config.get(\"wd_max\", 1e-4),\n",
    "                                       log=True)\n",
    "    batch_size = trial.suggest_int(\"batch_size\",\n",
    "                                   config.get(\"batch_size_min\", 32),\n",
    "                                   config.get(\"batch_size_max\", 128),\n",
    "                                   step=config.get(\"batch_size_step\", 16))\n",
    "    patience = config.get(\"patience\", 10)\n",
    "    epochs = config.get(\"epochs\", 5)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True) # Load the train DataLoader with the chosen batch_size\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False) # Load the val DataLoader with the chosen batch_size\n",
    "\n",
    "    # Define optimizer and loss function\n",
    "    criterion = config.get(\"criterion\", nn.CrossEntropyLoss()) # Classification.\n",
    "    optimizer_class = config.get(\"optimizer_class\", optim.Adam)\n",
    "    optimizer = optimizer_class(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "    # Initialize Weights & Biases - the values in the config are the properties of each trial.\n",
    "    architecture = getattr(model, \"architecture\", model.__class__.__name__)\n",
    "    wandb.init(project=\"deep_van_gogh\",\n",
    "               config={\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"weight_decay\": weight_decay,\n",
    "        \"patience\": patience,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"epochs\": epochs,\n",
    "        \"architecture\": architecture,\n",
    "        \"dataset\": config.get(\"dataset_name\", \"Post_Impressionism\")\n",
    "    },\n",
    "    name=f\"{architecture}_trial_{trial.number}\") # The name that will be saved in the W&B platform\n",
    "\n",
    "    # Train the model and get the best validation loss\n",
    "    best_val_loss = train_model_with_hyperparams(model, train_loader, val_loader, optimizer, criterion,\n",
    "                                                 epochs=epochs, patience=patience, device=device, trial=trial,\n",
    "                                                 architecture=architecture)\n",
    "\n",
    "    # Finish the Weights & Biases run\n",
    "    wandb.finish()\n",
    "\n",
    "    # Return best validation loss as the objective to minimize\n",
    "    return best_val_loss\n",
    "\n",
    "# TODO:\n",
    "# make an objective with best accuracy\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T15:15:58.965239Z",
     "start_time": "2025-01-22T15:15:58.952224Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Cross-Validation"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T18:09:34.518973Z",
     "start_time": "2025-01-22T18:09:34.505946Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def cross_validation(dataset:Dataset, **models_dict):\n",
    "    # Initialize KFold\n",
    "    k_folds = 5\n",
    "    kfold = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "\n",
    "    # Track performance for each model\n",
    "    results = defaultdict(list)\n",
    "\n",
    "    for fold, (train_ids, val_ids) in enumerate(kfold.split(dataset)):\n",
    "            print(f\"\\tFold {fold + 1}\")\n",
    "            # Subset the dataset for this fold\n",
    "            train_subset = Subset(dataset, train_ids)\n",
    "            val_subset = Subset(dataset, val_ids)\n",
    "\n",
    "            # Create data loaders\n",
    "            train_loader = DataLoader(train_subset, batch_size=64, shuffle=True)\n",
    "            val_loader = DataLoader(val_subset, batch_size=64, shuffle=False)\n",
    "\n",
    "            for model_name, model_dict in models_dict.items():\n",
    "                print(f\"Training :{model_name}\")\n",
    "                # Load the entire model\n",
    "                base_model = vgg19 if model_dict[\"architecture\"] == VGG19 else alexnet\n",
    "                model = FinedTunedModel(base_model.to(device), model_dict[\"architecture\"]).to(device)\n",
    "\n",
    "                # Define loss function and optimizer\n",
    "                criterion = nn.CrossEntropyLoss()\n",
    "                optimizer = optim.Adam(model.parameters(), **model_dict['param_groups'])\n",
    "\n",
    "\n",
    "\n",
    "                # Train the model (implement your training loop here)\n",
    "                best_val_loss = train_model_with_hyperparams(model, train_loader, val_loader, optimizer, criterion,\n",
    "                                                             epochs=3, patience=3, device=device, trial=None,\n",
    "                                                             architecture=None)\n",
    "                 # Append the results for this fold\n",
    "                results[model_name].append(best_val_loss)\n",
    "\n",
    "\n",
    "    # Print final results\n",
    "    for model_name, model_results in results.items():\n",
    "         # After all folds, calculate the average fold performance\n",
    "        mean_perf = sum(results[model_name]) / len(results[model_name])\n",
    "        print(f\"Average Performance for {model_name}: {mean_perf}\")\n",
    "\n",
    "        print(f\"{model_name} - Cross-Validation Results: {model_results}\")\n",
    "        print(f\"{model_name} - Mean Performance: {sum(model_results) / len(model_results)}\")"
   ],
   "outputs": [],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T18:12:25.133552Z",
     "start_time": "2025-01-22T18:09:35.021822Z"
    }
   },
   "cell_type": "code",
   "source": [
    "vgg_path = os.path.join(utils.MODELS_DIR, VGG19)\n",
    "\n",
    "def get_hyperparameters(path):\n",
    "    param_groups = torch.load(path, weights_only=True)['optimizer_state_dict']['param_groups'][0]\n",
    "    return {'lr':param_groups['lr'], 'weight_decay':param_groups['weight_decay']}\n",
    "\n",
    "\n",
    "model1_param_groups = get_hyperparameters(f\"{vgg_path}/best_model_trial_0.pt\") # Load hyperparameters\n",
    "model1_dict = {\n",
    "    'architecture': VGG19,\n",
    "    'param_groups': model1_param_groups\n",
    "}\n",
    "\n",
    "\n",
    "model2_param_groups =  get_hyperparameters(f\"{vgg_path}/best_model_trial_1.pt\") # Load hyperparameters\n",
    "model2_dict = {\n",
    "    'architecture': VGG19,\n",
    "    'param_groups': model2_param_groups\n",
    "}\n",
    "\n",
    "\n",
    "cross_validation(train_dataset, vgg_model1=model1_dict, vgg_model2=model2_dict)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tFold 1\n",
      "Training :vgg_model1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T18:12:27.973935Z",
     "start_time": "2025-01-22T18:12:27.963935Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vIb8Ud6FiGuu"
   },
   "source": [
    "# Fine tuning AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "gaSN21pPiGdy",
    "outputId": "8101799f-ef2c-4ada-8a3d-7dc594b2385e",
    "ExecuteTime": {
     "end_time": "2025-01-22T14:01:31.826326Z",
     "start_time": "2025-01-22T14:01:30.798859Z"
    }
   },
   "source": [
    "# Load the AlexNet model \n",
    "alexnet = models.alexnet(weights=models.AlexNet_Weights.DEFAULT).to(device)\n",
    "alexnet_model = FinedTunedModel(alexnet, ALEXNET).to(device)\n",
    "alexnet_model"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FinedTunedModel(\n",
       "  (features_extractor): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (4): ReLU(inplace=True)\n",
       "      (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (7): ReLU(inplace=True)\n",
       "      (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (9): ReLU(inplace=True)\n",
       "      (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (11): ReLU(inplace=True)\n",
       "      (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (1): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=4096, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T14:02:50.693818Z",
     "start_time": "2025-01-22T14:01:36.162625Z"
    }
   },
   "source": [
    "study = optuna.create_study(study_name=f'{ALEXNET}', direction='minimize')\n",
    "study.optimize(lambda trial: objective(trial, alexnet_model, config={}), n_trials=3)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-22 16:01:36,164] A new study created in memory with name: AlexNet\n",
      "wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "wandb: Currently logged in as: amitr5 (amitr5-tel-aviv-university). Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.19.1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>C:\\Projects\\deep_van_gogh\\wandb\\run-20250122_160137-1kactwlt</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/amitr5-tel-aviv-university/deep_van_gogh/runs/1kactwlt' target=\"_blank\">AlexNet_trial_0</a></strong> to <a href='https://wandb.ai/amitr5-tel-aviv-university/deep_van_gogh' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/amitr5-tel-aviv-university/deep_van_gogh' target=\"_blank\">https://wandb.ai/amitr5-tel-aviv-university/deep_van_gogh</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/amitr5-tel-aviv-university/deep_van_gogh/runs/1kactwlt' target=\"_blank\">https://wandb.ai/amitr5-tel-aviv-university/deep_van_gogh/runs/1kactwlt</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▃▅▆█</td></tr><tr><td>Train Accuracy</td><td>▁▅▆▇█</td></tr><tr><td>Train Loss</td><td>█▃▂▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁█▆▇▆</td></tr><tr><td>Validation Loss</td><td>█▁▅▂▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>5</td></tr><tr><td>Train Accuracy</td><td>0.99795</td></tr><tr><td>Train Loss</td><td>0.01104</td></tr><tr><td>Validation Accuracy</td><td>0.96854</td></tr><tr><td>Validation Loss</td><td>0.11455</td></tr></table><br/></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">AlexNet_trial_0</strong> at: <a href='https://wandb.ai/amitr5-tel-aviv-university/deep_van_gogh/runs/1kactwlt' target=\"_blank\">https://wandb.ai/amitr5-tel-aviv-university/deep_van_gogh/runs/1kactwlt</a><br> View project at: <a href='https://wandb.ai/amitr5-tel-aviv-university/deep_van_gogh' target=\"_blank\">https://wandb.ai/amitr5-tel-aviv-university/deep_van_gogh</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250122_160137-1kactwlt\\logs</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-22 16:01:57,725] Trial 0 finished with value: 0.10576229227551358 and parameters: {'learning_rate': 8.54475681264745e-05, 'weight_decay': 1.3246324576641997e-06, 'batch_size': 96}. Best is trial 0 with value: 0.10576229227551358.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.19.1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>C:\\Projects\\deep_van_gogh\\wandb\\run-20250122_160157-0a23wi5w</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/amitr5-tel-aviv-university/deep_van_gogh/runs/0a23wi5w' target=\"_blank\">AlexNet_trial_1</a></strong> to <a href='https://wandb.ai/amitr5-tel-aviv-university/deep_van_gogh' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/amitr5-tel-aviv-university/deep_van_gogh' target=\"_blank\">https://wandb.ai/amitr5-tel-aviv-university/deep_van_gogh</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/amitr5-tel-aviv-university/deep_van_gogh/runs/0a23wi5w' target=\"_blank\">https://wandb.ai/amitr5-tel-aviv-university/deep_van_gogh/runs/0a23wi5w</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▃▅▆█</td></tr><tr><td>Train Accuracy</td><td>▁▅▆▇█</td></tr><tr><td>Train Loss</td><td>█▃▂▂▁</td></tr><tr><td>Validation Accuracy</td><td>▅█▁▄▃</td></tr><tr><td>Validation Loss</td><td>▂▂▂▁█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>5</td></tr><tr><td>Train Accuracy</td><td>0.98598</td></tr><tr><td>Train Loss</td><td>0.04482</td></tr><tr><td>Validation Accuracy</td><td>0.95896</td></tr><tr><td>Validation Loss</td><td>0.3491</td></tr></table><br/></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">AlexNet_trial_1</strong> at: <a href='https://wandb.ai/amitr5-tel-aviv-university/deep_van_gogh/runs/0a23wi5w' target=\"_blank\">https://wandb.ai/amitr5-tel-aviv-university/deep_van_gogh/runs/0a23wi5w</a><br> View project at: <a href='https://wandb.ai/amitr5-tel-aviv-university/deep_van_gogh' target=\"_blank\">https://wandb.ai/amitr5-tel-aviv-university/deep_van_gogh</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250122_160157-0a23wi5w\\logs</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-22 16:02:24,856] Trial 1 finished with value: 0.12651337678614297 and parameters: {'learning_rate': 0.00035744717416844876, 'weight_decay': 3.63939834492625e-06, 'batch_size': 32}. Best is trial 0 with value: 0.10576229227551358.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.19.1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>C:\\Projects\\deep_van_gogh\\wandb\\run-20250122_160224-ipk3eviz</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/amitr5-tel-aviv-university/deep_van_gogh/runs/ipk3eviz' target=\"_blank\">AlexNet_trial_2</a></strong> to <a href='https://wandb.ai/amitr5-tel-aviv-university/deep_van_gogh' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/amitr5-tel-aviv-university/deep_van_gogh' target=\"_blank\">https://wandb.ai/amitr5-tel-aviv-university/deep_van_gogh</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/amitr5-tel-aviv-university/deep_van_gogh/runs/ipk3eviz' target=\"_blank\">https://wandb.ai/amitr5-tel-aviv-university/deep_van_gogh/runs/ipk3eviz</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▃▅▆█</td></tr><tr><td>Train Accuracy</td><td>▁▅▇██</td></tr><tr><td>Train Loss</td><td>█▃▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▇▄█▅</td></tr><tr><td>Validation Loss</td><td>▅▁█▁▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>5</td></tr><tr><td>Train Accuracy</td><td>0.98324</td></tr><tr><td>Train Loss</td><td>0.05421</td></tr><tr><td>Validation Accuracy</td><td>0.95896</td></tr><tr><td>Validation Loss</td><td>0.1584</td></tr></table><br/></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">AlexNet_trial_2</strong> at: <a href='https://wandb.ai/amitr5-tel-aviv-university/deep_van_gogh/runs/ipk3eviz' target=\"_blank\">https://wandb.ai/amitr5-tel-aviv-university/deep_van_gogh/runs/ipk3eviz</a><br> View project at: <a href='https://wandb.ai/amitr5-tel-aviv-university/deep_van_gogh' target=\"_blank\">https://wandb.ai/amitr5-tel-aviv-university/deep_van_gogh</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250122_160224-ipk3eviz\\logs</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-22 16:02:50,670] Trial 2 finished with value: 0.131821774687776 and parameters: {'learning_rate': 0.0008391974354331484, 'weight_decay': 9.707033483493868e-05, 'batch_size': 32}. Best is trial 0 with value: 0.10576229227551358.\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "analysing results"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T11:14:45.934631Z",
     "start_time": "2025-01-22T11:14:45.917633Z"
    }
   },
   "source": "",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZMIPaYdChtVL"
   },
   "source": [
    "# Style transfer function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "LRQUj_gU93MT"
   },
   "outputs": [],
   "source": [
    "from PIL.Image import Image\n",
    "\n",
    "\n",
    "#define a function to load an image and pre-process it\n",
    "def load_image(img_path, shape=(224, 224)):\n",
    "    image = Image.open(img_path).convert('RGB')\n",
    "    # Define transformation to resize, normalize, and convert to tensor\n",
    "    in_transform = transforms.Compose([\n",
    "        transforms.Resize(shape),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "    ])\n",
    "    # Apply transformations, remove alpha channel, and add batch dimension\n",
    "    image = in_transform(image)[:3, :, :].unsqueeze(0)\n",
    "    return image.to(device)\n",
    "#define a function to extract features from the network\n",
    "def get_features(image, model, layers):\n",
    "    features = {}\n",
    "    x = image\n",
    "    for name, layer in model._modules.items():\n",
    "        x = layer(x)\n",
    "        if name in layers:\n",
    "            features[layers[name]] = x\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "collapsed": true,
    "id": "yhlrhEFw4Vm6",
    "outputId": "278d8206-40e6-4266-a1f8-38c87411a3f7"
   },
   "outputs": [],
   "source": [
    "def style_transfer(model, style_img_path, content_img_path, content_weight=1, style_weight=1e3, num_steps=5001, model_name='vgg19_pretrained'):\n",
    "    model = model.features #Gives us access to the layers of features\n",
    "\n",
    "    layers = {\n",
    "         '0': 'conv1_1', '5': 'conv2_1', '10': 'conv3_1', '19': 'conv4_1',\n",
    "         '21': 'conv4_2'\n",
    "    }\n",
    "\n",
    "    style_weights = {\n",
    "        'conv1_1': 0.5, 'conv2_1': 0.5, 'conv3_1': 0.5, 'conv4_1': 0.3\n",
    "    }\n",
    "\n",
    "    content_layer = 'conv4_2'\n",
    "    # Prepare model for evaluation, disabling gradient computation\n",
    "    model.to(device).eval()\n",
    "    for param in model.parameters():\n",
    "         param.requires_grad_(False)\n",
    "        # Load and preprocess the content and style images\n",
    "    content = load_image(content_img_path).to(device)\n",
    "    style = load_image(style_img_path).to(device)\n",
    "         # Extract features from content and style images\n",
    "    content_features = get_features(content, model, layers)\n",
    "    style_features = get_features(style, model, layers)\n",
    "    target = content.clone().requires_grad_(True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "gy8lmbPmhj9H",
    "outputId": "330638de-9f78-4d50-c423-bbab448afc37"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 196
    },
    "id": "2cMigqU0CGg5",
    "outputId": "afdc3a89-f2ad-457b-eeb7-b4aabcf214ca"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "2UNqmGA2DXDj",
    "outputId": "18e5c745-d27d-4f23-97cf-717b194bd3c3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-dC9MS7V6WZF",
    "outputId": "80757501-0728-4fe1-96b7-a15122faad92"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w93PNhRgHVue",
    "outputId": "704e1556-8d2f-4c90-af0e-bc26aa7a072e"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "24UKrxg-H25c"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "name": "python3",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
