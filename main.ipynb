{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T06:36:30.177076Z",
     "start_time": "2025-01-13T06:36:30.118780Z"
    }
   },
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision import transforms, models\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "from torch.utils.data import Dataset, DataLoader, Subset, ConcatDataset\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision.models import VGG19_Weights\n",
    "\n",
    "# Project utilities\n",
    "import utils\n",
    "import preprocessing\n",
    "import optuna\n",
    "import wandb\n",
    "\n",
    "# Set seed\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "# torch.backends.cudnn.deterministic = True\n",
    "# torch.use_deterministic_algorithms = True\n",
    "\n",
    "\n",
    "ROOT = './data'\n",
    "DATASET_DIR = './data/Post_Impressionism'\n",
    "CSV_PATH = './data/classes.csv'\n",
    "\n",
    "if not (os.path.exists(DATASET_DIR) and os.path.exists(CSV_PATH)):\n",
    "    raise FileExistsError(\"File doesn't exist, we expect a data folder with the labels and the images folder as in the lab\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "outputs": [],
   "execution_count": 99
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T06:36:30.969611Z",
     "start_time": "2025-01-13T06:36:30.527613Z"
    }
   },
   "cell_type": "code",
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(), # Convert the image to a PyTorch tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229,0.224, 0.225])]) # Normalize the pixel values based on ImageNet statistics, to a range that VGG expects\n",
    "\n",
    "dataset = preprocessing.ImageFolderForBinaryClassification(root=ROOT, target='is_van_gogh', transform=transform)\n",
    "# Take only pictures that are in inside the csv\n",
    "pics_in_csv = [i for i in range(len(dataset)) if dataset.samples[i][1] >= 0]\n",
    "dataset = Subset(dataset, pics_in_csv)"
   ],
   "outputs": [],
   "execution_count": 100
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T06:43:09.016893Z",
     "start_time": "2025-01-13T06:43:08.971892Z"
    }
   },
   "cell_type": "code",
   "source": [
    "classes = pd.read_csv(CSV_PATH)\n",
    "train_classes = classes[classes['subset'] == 'train']\n",
    "test_classes = classes[classes['subset'] == 'test']\n",
    "\n",
    "train_indices, val_indices = train_test_split(train_classes.index.to_list(), test_size=0.2, random_state=SEED)\n",
    "train_dataset = Subset(dataset, train_indices)\n",
    "val_dataset = Subset(dataset, val_indices)"
   ],
   "outputs": [],
   "execution_count": 113
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Data Augmentation"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T06:43:10.932947Z",
     "start_time": "2025-01-13T06:43:10.558900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "n_times = 25\n",
    "dropout_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    *([transforms.RandomErasing(p=0.5, scale=(0.01, 0.01), ratio=(1, 1))]*n_times),\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229,0.224, 0.225])\n",
    "])\n",
    "dropout_dataset = Subset(preprocessing.ImageFolderForBinaryClassification(root=ROOT, transform=dropout_transform, target='is_van_gogh'), train_indices)\n",
    "augmented_train_dataset = ConcatDataset([dropout_dataset, train_dataset])"
   ],
   "outputs": [],
   "execution_count": 114
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T06:44:05.269748Z",
     "start_time": "2025-01-13T06:44:05.236747Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_loader = DataLoader(augmented_train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)"
   ],
   "outputs": [],
   "execution_count": 115
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jFD4XwIchub9"
   },
   "source": [
    "# Fine tuning VGG19"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Ug6-1DB33fkH",
    "outputId": "03123ea9-33d7-447f-ad37-ed54df78747e",
    "ExecuteTime": {
     "end_time": "2025-01-13T08:06:28.093602Z",
     "start_time": "2025-01-13T08:06:25.906566Z"
    }
   },
   "source": [
    "# Load pre-trained VGG19 model\n",
    "# vgg19 = models.vgg19(pretrained=True)\n",
    "vgg19 = models.vgg19(weights=models.VGG19_Weights.DEFAULT).to(device)"
   ],
   "outputs": [],
   "execution_count": 117
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T21:28:17.108682Z",
     "start_time": "2025-01-09T21:28:17.097671Z"
    }
   },
   "source": [
    "from train import train_model_with_hyperparams\n",
    "\n",
    "# Optuna objective function\n",
    "def objective(trial):\n",
    "    # Hyperparameter suggestions\n",
    "    learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-3) #Suggests a learning_rate value from a log-uniform distribution between 1e-5 and 1e-3 for hyperparameter optimization using Optuna.\n",
    "    weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-6, 1e-4) # Suggests a weight_decay value from a log-uniform distribution between 1e-6 and 1e-4 for regularization during Optuna hyperparameter optimization.\n",
    "    patience = trial.suggest_int(\"patience\", 3, 10) #I don't really like putting the patience as an hyper parameter - this is a thing that needs to be determined according to constraints. I put it here just to show that this is possible.\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 16, 64, step=16) # Basically choosing between 16,32,64\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True) # Load the train DataLoader with the chosen batch_size\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False) # Load the val DataLoader with the chosen batch_size\n",
    "\n",
    "    # Load the pre-trained model VGG16\n",
    "    model = models.vgg16(pretrained=True) # pretrained=True == with the trained weights\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Freeze layers\n",
    "    for param in model.features.parameters():\n",
    "        param.requires_grad = False\n",
    "    # Unfreeze the last 6 layers in the features part of the VGG\n",
    "    for param in model.features[-6:].parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "    # Modify the classifier to fit our problem (10 classes)\n",
    "    model.classifier[6] = nn.Linear(4096, 10) # Replaces the final layer of the VGG16 classifier with a new fully connected (nn.Linear) layer. The new wights are initialized randomly and hence will need to be trained\n",
    "    model.classifier[6] = model.classifier[6].to(device)\n",
    "\n",
    "    # Define optimizer and loss function\n",
    "    criterion = nn.CrossEntropyLoss() # Classification.\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay) # Adam, like always, with the chosen parameters from Optuna\n",
    "\n",
    "    # Initialize Weights & Biases - the values in the config are the properties of each trial.\n",
    "    wandb.init(project=\"project-vgg19\", #init == set the project and the \"general\" parameters\n",
    "               config={\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"weight_decay\": weight_decay,\n",
    "        \"patience\": patience,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"architecture\": \"VGG19\",\n",
    "        \"dataset\": \"Post_Imp-10\"\n",
    "    },\n",
    "    name=f\"trial_{trial.number}\") # The name that will be saved in the W&B platform\n",
    "\n",
    "    # Train the model and get the best validation loss\n",
    "    best_val_loss = train_model_with_hyperparams(model, train_loader, val_loader, optimizer, criterion, epochs=20, patience=patience, trial=trial) #send this trinal to the function above\n",
    "\n",
    "    # Finish the Weights & Biases run\n",
    "    wandb.finish()\n",
    "\n",
    "    # Return best validation loss as the objective to minimize\n",
    "    return best_val_loss"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG19_Weights.IMAGENET1K_V1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vIb8Ud6FiGuu"
   },
   "source": [
    "# Fine tuning AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "gaSN21pPiGdy",
    "outputId": "8101799f-ef2c-4ada-8a3d-7dc594b2385e"
   },
   "outputs": [],
   "source": [
    "# Load the AlexNet model \n",
    "alexnet = models.alexnet(pretrained=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "analysing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZMIPaYdChtVL"
   },
   "source": [
    "# Style transfer function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "LRQUj_gU93MT"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "collapsed": true,
    "id": "yhlrhEFw4Vm6",
    "outputId": "278d8206-40e6-4266-a1f8-38c87411a3f7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "gy8lmbPmhj9H",
    "outputId": "330638de-9f78-4d50-c423-bbab448afc37"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 196
    },
    "id": "2cMigqU0CGg5",
    "outputId": "afdc3a89-f2ad-457b-eeb7-b4aabcf214ca"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "2UNqmGA2DXDj",
    "outputId": "18e5c745-d27d-4f23-97cf-717b194bd3c3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-dC9MS7V6WZF",
    "outputId": "80757501-0728-4fe1-96b7-a15122faad92"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w93PNhRgHVue",
    "outputId": "704e1556-8d2f-4c90-af0e-bc26aa7a072e"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "24UKrxg-H25c"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "name": "python3",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
