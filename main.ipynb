{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-29T19:09:09.723244Z",
     "start_time": "2025-03-29T19:09:00.232285Z"
    }
   },
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
    "from sympy.physics.units import length\n",
    "from torchvision import transforms, models\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "\n",
    "from collections import defaultdict\n",
    "from optuna import trial\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, Subset, ConcatDataset\n",
    "import optuna\n",
    "import wandb\n",
    "# Project utilities\n",
    "import utils\n",
    "import importlib\n",
    "import train\n",
    "importlib.reload(train)\n",
    "importlib.reload(utils)\n",
    "from train import train_model_with_hyperparams\n",
    "\n",
    "VGG19 = 'VGG19'\n",
    "ALEXNET = 'AlexNet'\n",
    "\n",
    "# Set seed\n",
    "SEED = utils.SEED\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-29T19:09:09.770243Z",
     "start_time": "2025-03-29T19:09:09.730247Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Check if you're working locally or not\n",
    "if not (os.path.exists(utils.CSV_PATH) and os.path.exists(utils.OPTIMIZED_DIR)):\n",
    "    print(f\"[!] You are NOT on the project's directory [!]\\n\"\n",
    "          f\"Please run the following command (in either CMD or anaconda prompt): \\n\"\n",
    "          f\"jupyter notebook --notebook-dir PROJECT_DIR\\n\"\n",
    "          r\"Where PROJECT_DIR is the project's directory in your computer e.g: C:\\Users\\amitr5\\PycharmProjects\\deep_van_gogh\")"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Loading our data\n",
    "We will load the optimized datasets from our custom dataset object\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-29T19:09:18.108036Z",
     "start_time": "2025-03-29T19:09:09.804246Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class NumPyDataset(Dataset):\n",
    "    def __init__(self, file_path):\n",
    "        data = np.load(file_path)\n",
    "        self.images = data[\"images\"]\n",
    "        self.labels = data[\"labels\"]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = torch.tensor(self.images[idx], dtype=torch.float32)\n",
    "        y = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        return x, y\n",
    "\n",
    "dataset = NumPyDataset(os.path.join(utils.OPTIMIZED_DIR, 'dataset.npz'))"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "You can find the optimized dataset files <a href=\"https://drive.google.com/drive/folders/1TBlNcRsRHJ7_rxh_h7_yn_-Ak66Uj_mp?usp=sharing\">HERE</a><br/>\n",
    "Loading the train and test datasets:"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-29T21:11:36.921926Z",
     "start_time": "2025-03-29T21:11:36.893730Z"
    }
   },
   "cell_type": "code",
   "source": [
    "classes = pd.read_csv(utils.CSV_PATH)\n",
    "train_rows = classes[classes['subset'] == 'train']\n",
    "train_indices, val_indices = train_test_split(train_rows.index.to_list(), test_size=0.2, random_state=utils.SEED, stratify=train_rows['is_van_gogh'])\n",
    "train_dataset = Subset(dataset, train_indices)\n",
    "val_dataset = Subset(dataset, val_indices)\n",
    "test_dataset = Subset(dataset, classes[classes['subset'] == 'test'].index.tolist()).dataset"
   ],
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-29T21:13:28.147354Z",
     "start_time": "2025-03-29T21:13:18.218658Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_opt_dataset(dataset_name, train_idx=None, val_idx=None):\n",
    "    data = NumPyDataset(os.path.join(utils.OPTIMIZED_DIR, f'{dataset_name}.npz'))\n",
    "    if train_idx and val_idx:\n",
    "        return Subset(data, train_idx), Subset(data, val_idx)\n",
    "\n",
    "    return Subset(data, train_idx if train_idx else val_idx).dataset\n",
    "\n",
    "flip_dataset = get_opt_dataset('flip', train_indices)\n",
    "dropout_dataset = get_opt_dataset('dropout',train_indices)\n",
    "affine_dataset = get_opt_dataset('affine', train_indices)\n",
    "blur_dataset = get_opt_dataset('blur', train_indices)\n",
    "#\n",
    "augmented_train_dataset = ConcatDataset([train_dataset, flip_dataset, dropout_dataset, affine_dataset, blur_dataset])\n",
    "\n",
    "# augmented_train_dataset = train_dataset\n",
    "train_loader = DataLoader(augmented_train_dataset, batch_size=128, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)"
   ],
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Data Augmentation"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "For a detailed explanation about our data augmentation, please check augmentation_demo.ipynb"
  },
  {
   "metadata": {
    "id": "jFD4XwIchub9"
   },
   "cell_type": "markdown",
   "source": "# Fine tuning VGG19"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-29T19:09:27.388573Z",
     "start_time": "2025-03-29T19:09:27.379576Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 7,
   "source": [
    "class FinedTunedModel(nn.Module):\n",
    "    def __init__(self, base_model, architecture:str):\n",
    "        super(FinedTunedModel, self).__init__()\n",
    "        self._architecture = architecture  # Save the base model architecture\n",
    "        base_children_list = list(base_model.children())\n",
    "        self.features_extractor = nn.Sequential(*base_children_list[:-1]).to(device)\n",
    "        for param in self.features_extractor.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        # Modify the classifier to fit to our problem (2 classes)\n",
    "        self.classifier = nn.Sequential(*base_children_list[-1])\n",
    "        self.classifier[-1] = nn.Linear(4096, 2).to(device)  # Replaces the final layer of the base model's classifier with a new fully connected layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        base_model_output = self.features_extractor(x)\n",
    "        return self.classifier(torch.flatten(base_model_output, start_dim=1))\n",
    "    @property\n",
    "    def architecture(self):\n",
    "        return self._architecture"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-29T19:09:31.572114Z",
     "start_time": "2025-03-29T19:09:27.407572Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 8,
   "source": [
    "# Load pre-trained models\n",
    "vgg19 = models.vgg19(weights=models.VGG19_Weights.DEFAULT).to(device)\n",
    "alexnet = models.alexnet(weights=models.AlexNet_Weights.DEFAULT).to(device)"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-29T19:31:12.582933Z",
     "start_time": "2025-03-29T19:31:12.558716Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def cross_validation(learning_rate,\n",
    "                     weight_decay,\n",
    "                     num_layers_finetune,\n",
    "                     criterion,\n",
    "                     epochs,\n",
    "                     patience,\n",
    "                     device,\n",
    "                     architecture,\n",
    "                     batch_size=128, trial=None, project='project'):\n",
    "    k_folds = 4\n",
    "    kfold = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "\n",
    "    labels = []\n",
    "    for dataset in augmented_train_dataset.datasets:\n",
    "        labels.extend([label for _, label in dataset])\n",
    "\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    # Track performance for each model\n",
    "    base_model = vgg19 if architecture == VGG19 else alexnet\n",
    "    best_values = []\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(kfold.split(np.zeros(len(labels)), labels)):\n",
    "        wandb.init(project = project,\n",
    "                       config={ \"learning_rate\": learning_rate,\n",
    "                                \"weight_decay\": weight_decay,\n",
    "                                \"patience\": patience,\n",
    "                                \"batch_size\": batch_size,\n",
    "                                \"epochs\": epochs,\n",
    "                                \"num_layers_finetune\": num_layers_finetune,\n",
    "                                \"fold\": fold,\n",
    "                                \"architecture\": architecture,\n",
    "                                \"dataset\": \"Post_Impressionism\",\n",
    "                                }, name=f\"{architecture}_trial_{trial.number + 1 if trial else -1}_fold_{fold}\")\n",
    "\n",
    "        train_subset = Subset(augmented_train_dataset, train_idx)\n",
    "        val_subset = Subset(augmented_train_dataset, val_idx)\n",
    "\n",
    "        # Create data loaders\n",
    "        train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False)\n",
    "        model = FinedTunedModel(base_model, architecture).to(device)\n",
    "        if num_layers_finetune:\n",
    "            for param in model.features_extractor[-num_layers_finetune:].parameters():\n",
    "                param.requires_grad = True\n",
    "\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "        # Train the model\n",
    "        best_metrics = train_model_with_hyperparams(model,\n",
    "                                                train_loader,\n",
    "                                                val_loader,\n",
    "                                                optimizer,\n",
    "                                                criterion,\n",
    "                                                epochs=epochs,\n",
    "                                                patience=patience,\n",
    "                                                device=device,\n",
    "                                                trial=trial,\n",
    "                                                architecture=architecture, fold=fold)\n",
    "        best_values.append(best_metrics)\n",
    "        # Finish the Weights & Biases run\n",
    "        wandb.finish()\n",
    "    mean_dict = utils.mean_dict(best_values)\n",
    "    return mean_dict\n"
   ],
   "outputs": [],
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-29T19:31:23.383022Z",
     "start_time": "2025-03-29T19:31:23.355646Z"
    }
   },
   "source": [
    "def objective(trial, architecture, config: dict) -> float:\n",
    "    \"\"\"\n",
    "    Generic Optuna objective function.\n",
    "    :param trial: Optuna trial object.\n",
    "    :param model: The neural network model to train\n",
    "    :param config: A dictionary with configurable values such as learning rate ranges, batch size ranges, etc.\n",
    "    :return:  best_val_loss: The best validation loss achieved during training.\n",
    "    \"\"\"\n",
    "    # Hyperparameter suggestions based on config\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\",\n",
    "                                        config.get(\"lr_min\", 1e-5),\n",
    "                                        config.get(\"lr_max\", 1e-3),\n",
    "                                        log=True)\n",
    "    weight_decay = trial.suggest_float(\"weight_decay\",\n",
    "                                       config.get(\"wd_min\", 1e-6),\n",
    "                                       config.get(\"wd_max\", 1e-4),\n",
    "                                       log=True)\n",
    "    # Including the option not to perform fine-tuning, or only a small num of layers within the feature extractor.\n",
    "    num_layers_finetune = trial.suggest_int(\"num_layers_finetune\", 0, 3)\n",
    "    # batch_size = trial.suggest_int(\"batch_size\",\n",
    "    #                                config.get(\"batch_size_min\", 32),\n",
    "    #                                config.get(\"batch_size_max\", 128),\n",
    "    #                                step=config.get(\"batch_size_step\", 16))\n",
    "    batch_size = 128\n",
    "    # epochs = trial.suggest_int(\"epochs\", config.get(\"epochs_min\", 10), config.get(\"epochs_max\",30))\n",
    "    epochs = trial.suggest_int(\"epochs\", config.get(\"epochs_min\", 3), config.get(\"epochs_max\",4))\n",
    "    patience = config.get(\"patience\", 8)\n",
    "\n",
    "    # Define optimizer and loss function\n",
    "    criterion = config.get(\"criterion\", nn.CrossEntropyLoss()) # Classification.\n",
    "\n",
    "    project = 'deep_van_gogh-112311'\n",
    "    # Train the model and get the best mean val_auc\n",
    "    mean_dict = cross_validation(learning_rate, weight_decay, num_layers_finetune, criterion, epochs, patience, device, architecture, batch_size, trial, project=project)\n",
    "    # Log the mean values\n",
    "    wandb.init(project = project,\n",
    "                       config={ \"learning_rate\": learning_rate,\n",
    "                                \"weight_decay\": weight_decay,\n",
    "                                \"patience\": patience,\n",
    "                                \"batch_size\": batch_size,\n",
    "                                \"epochs\": epochs,\n",
    "                                \"num_layers_finetune\": num_layers_finetune,\n",
    "                                \"architecture\": architecture,\n",
    "                                \"dataset\": \"Post_Impressionism\",\n",
    "                                }, name=f\"{architecture}_trial_{trial.number + 1 if trial else -1}\")\n",
    "    # Return best validation loss as the objective to minimize\n",
    "    return mean_dict['Validation AUC']\n"
   ],
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-29T19:32:17.783498Z",
     "start_time": "2025-03-29T19:31:26.085568Z"
    }
   },
   "cell_type": "code",
   "source": [
    "n_trials = 10\n",
    "study = optuna.create_study(study_name=VGG19, direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, VGG19, config={}), n_trials=n_trials)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 22:31:26,089] A new study created in memory with name: AlexNet\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▅█</td></tr><tr><td>Train Accuracy</td><td>▁█▁</td></tr><tr><td>Train Loss</td><td>▇▁█</td></tr><tr><td>Validation AUC</td><td>▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▁█</td></tr><tr><td>Validation F1</td><td>▁▁█</td></tr><tr><td>Validation Loss</td><td>▃█▁</td></tr><tr><td>Validation Precision</td><td>▁▁█</td></tr><tr><td>Validation Recall</td><td>▁▁█</td></tr><tr><td>Validation Specificity</td><td>█▁█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>3</td></tr><tr><td>Train Accuracy</td><td>0.99749</td></tr><tr><td>Train Loss</td><td>0.01106</td></tr><tr><td>Validation AUC</td><td>1</td></tr><tr><td>Validation Accuracy</td><td>1</td></tr><tr><td>Validation F1</td><td>1</td></tr><tr><td>Validation Loss</td><td>1e-05</td></tr><tr><td>Validation Precision</td><td>1</td></tr><tr><td>Validation Recall</td><td>1</td></tr><tr><td>Validation Specificity</td><td>1</td></tr></table><br/></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">AlexNet_trial_1</strong> at: <a href='https://wandb.ai/amitr5-tel-aviv-university/deep_van_gogh-11237/runs/v9v18ige' target=\"_blank\">https://wandb.ai/amitr5-tel-aviv-university/deep_van_gogh-11237/runs/v9v18ige</a><br> View project at: <a href='https://wandb.ai/amitr5-tel-aviv-university/deep_van_gogh-11237' target=\"_blank\">https://wandb.ai/amitr5-tel-aviv-university/deep_van_gogh-11237</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250329_222719-v9v18ige\\logs</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.19.1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>C:\\Projects\\deep_van_gogh\\wandb\\run-20250329_223138-g08y2ieo</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/amitr5-tel-aviv-university/deep_van_gogh-112311/runs/g08y2ieo' target=\"_blank\">AlexNet_trial_1_fold_1</a></strong> to <a href='https://wandb.ai/amitr5-tel-aviv-university/deep_van_gogh-112311' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/amitr5-tel-aviv-university/deep_van_gogh-112311' target=\"_blank\">https://wandb.ai/amitr5-tel-aviv-university/deep_van_gogh-112311</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/amitr5-tel-aviv-university/deep_van_gogh-112311/runs/g08y2ieo' target=\"_blank\">https://wandb.ai/amitr5-tel-aviv-university/deep_van_gogh-112311/runs/g08y2ieo</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▅█</td></tr><tr><td>Train Accuracy</td><td>▁██</td></tr><tr><td>Train Loss</td><td>█▁▁</td></tr><tr><td>Validation AUC</td><td>▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁██</td></tr><tr><td>Validation F1</td><td>▁██</td></tr><tr><td>Validation Loss</td><td>█▁▁</td></tr><tr><td>Validation Precision</td><td>▁██</td></tr><tr><td>Validation Recall</td><td>▁██</td></tr><tr><td>Validation Specificity</td><td>▁██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>3</td></tr><tr><td>Train Accuracy</td><td>0.99977</td></tr><tr><td>Train Loss</td><td>0.00076</td></tr><tr><td>Validation AUC</td><td>1</td></tr><tr><td>Validation Accuracy</td><td>1</td></tr><tr><td>Validation F1</td><td>1</td></tr><tr><td>Validation Loss</td><td>0.0</td></tr><tr><td>Validation Precision</td><td>1</td></tr><tr><td>Validation Recall</td><td>1</td></tr><tr><td>Validation Specificity</td><td>1</td></tr></table><br/></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">AlexNet_trial_1_fold_1</strong> at: <a href='https://wandb.ai/amitr5-tel-aviv-university/deep_van_gogh-112311/runs/g08y2ieo' target=\"_blank\">https://wandb.ai/amitr5-tel-aviv-university/deep_van_gogh-112311/runs/g08y2ieo</a><br> View project at: <a href='https://wandb.ai/amitr5-tel-aviv-university/deep_van_gogh-112311' target=\"_blank\">https://wandb.ai/amitr5-tel-aviv-university/deep_van_gogh-112311</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250329_223138-g08y2ieo\\logs</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.19.1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>C:\\Projects\\deep_van_gogh\\wandb\\run-20250329_223151-grgpfdc7</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/amitr5-tel-aviv-university/deep_van_gogh-112311/runs/grgpfdc7' target=\"_blank\">AlexNet_trial_1_fold_2</a></strong> to <a href='https://wandb.ai/amitr5-tel-aviv-university/deep_van_gogh-112311' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/amitr5-tel-aviv-university/deep_van_gogh-112311' target=\"_blank\">https://wandb.ai/amitr5-tel-aviv-university/deep_van_gogh-112311</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/amitr5-tel-aviv-university/deep_van_gogh-112311/runs/grgpfdc7' target=\"_blank\">https://wandb.ai/amitr5-tel-aviv-university/deep_van_gogh-112311/runs/grgpfdc7</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▅█</td></tr><tr><td>Train Accuracy</td><td>▁█▅</td></tr><tr><td>Train Loss</td><td>█▁▂</td></tr><tr><td>Validation AUC</td><td>▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>██▁</td></tr><tr><td>Validation F1</td><td>██▁</td></tr><tr><td>Validation Loss</td><td>▁▁█</td></tr><tr><td>Validation Precision</td><td>██▁</td></tr><tr><td>Validation Recall</td><td>██▁</td></tr><tr><td>Validation Specificity</td><td>██▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>3</td></tr><tr><td>Train Accuracy</td><td>0.99749</td></tr><tr><td>Train Loss</td><td>0.01364</td></tr><tr><td>Validation AUC</td><td>1</td></tr><tr><td>Validation Accuracy</td><td>0.99453</td></tr><tr><td>Validation F1</td><td>0.99466</td></tr><tr><td>Validation Loss</td><td>0.02271</td></tr><tr><td>Validation Precision</td><td>0.99504</td></tr><tr><td>Validation Recall</td><td>0.99453</td></tr><tr><td>Validation Specificity</td><td>0.99422</td></tr></table><br/></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">AlexNet_trial_1_fold_2</strong> at: <a href='https://wandb.ai/amitr5-tel-aviv-university/deep_van_gogh-112311/runs/grgpfdc7' target=\"_blank\">https://wandb.ai/amitr5-tel-aviv-university/deep_van_gogh-112311/runs/grgpfdc7</a><br> View project at: <a href='https://wandb.ai/amitr5-tel-aviv-university/deep_van_gogh-112311' target=\"_blank\">https://wandb.ai/amitr5-tel-aviv-university/deep_van_gogh-112311</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250329_223151-grgpfdc7\\logs</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.19.1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>C:\\Projects\\deep_van_gogh\\wandb\\run-20250329_223204-6dc2br66</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/amitr5-tel-aviv-university/deep_van_gogh-112311/runs/6dc2br66' target=\"_blank\">AlexNet_trial_1_fold_3</a></strong> to <a href='https://wandb.ai/amitr5-tel-aviv-university/deep_van_gogh-112311' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/amitr5-tel-aviv-university/deep_van_gogh-112311' target=\"_blank\">https://wandb.ai/amitr5-tel-aviv-university/deep_van_gogh-112311</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/amitr5-tel-aviv-university/deep_van_gogh-112311/runs/6dc2br66' target=\"_blank\">https://wandb.ai/amitr5-tel-aviv-university/deep_van_gogh-112311/runs/6dc2br66</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▅█</td></tr><tr><td>Train Accuracy</td><td>▁██</td></tr><tr><td>Train Loss</td><td>█▂▁</td></tr><tr><td>Validation AUC</td><td>▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▇█▁</td></tr><tr><td>Validation F1</td><td>▇█▁</td></tr><tr><td>Validation Loss</td><td>▁▁█</td></tr><tr><td>Validation Precision</td><td>▇█▁</td></tr><tr><td>Validation Recall</td><td>▇█▁</td></tr><tr><td>Validation Specificity</td><td>▇█▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>3</td></tr><tr><td>Train Accuracy</td><td>0.99909</td></tr><tr><td>Train Loss</td><td>0.00321</td></tr><tr><td>Validation AUC</td><td>1</td></tr><tr><td>Validation Accuracy</td><td>0.99521</td></tr><tr><td>Validation F1</td><td>0.99531</td></tr><tr><td>Validation Loss</td><td>0.01146</td></tr><tr><td>Validation Precision</td><td>0.99561</td></tr><tr><td>Validation Recall</td><td>0.99521</td></tr><tr><td>Validation Specificity</td><td>0.99495</td></tr></table><br/></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">AlexNet_trial_1_fold_3</strong> at: <a href='https://wandb.ai/amitr5-tel-aviv-university/deep_van_gogh-112311/runs/6dc2br66' target=\"_blank\">https://wandb.ai/amitr5-tel-aviv-university/deep_van_gogh-112311/runs/6dc2br66</a><br> View project at: <a href='https://wandb.ai/amitr5-tel-aviv-university/deep_van_gogh-112311' target=\"_blank\">https://wandb.ai/amitr5-tel-aviv-university/deep_van_gogh-112311</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250329_223204-6dc2br66\\logs</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.19.1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>C:\\Projects\\deep_van_gogh\\wandb\\run-20250329_223217-huxf7klj</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/amitr5-tel-aviv-university/deep_van_gogh-112311/runs/huxf7klj' target=\"_blank\">AlexNet_trial_1</a></strong> to <a href='https://wandb.ai/amitr5-tel-aviv-university/deep_van_gogh-112311' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/amitr5-tel-aviv-university/deep_van_gogh-112311' target=\"_blank\">https://wandb.ai/amitr5-tel-aviv-university/deep_van_gogh-112311</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/amitr5-tel-aviv-university/deep_van_gogh-112311/runs/huxf7klj' target=\"_blank\">https://wandb.ai/amitr5-tel-aviv-university/deep_van_gogh-112311/runs/huxf7klj</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 22:32:17,769] Trial 0 finished with value: 1.0 and parameters: {'learning_rate': 0.0003075583417190192, 'weight_decay': 5.55562224122944e-06, 'num_layers_finetune': 0, 'epochs': 3}. Best is trial 0 with value: 1.0.\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Cross-Validation"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-29T21:44:54.252994Z",
     "start_time": "2025-03-29T21:39:49.324191Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Training the model - ALEXNET\n",
    "base_model = vgg19\n",
    "model = FinedTunedModel(base_model.to(device), ALEXNET).to(device)\n",
    "weight_decay=0.0000961196621799138\n",
    "lr=0.0000607994047379646\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0000607994047379646, weight_decay=0.0000961196621799138)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "batch_size=128\n",
    "epochs=5\n",
    "wandb.init(project='deep_van_gogh-best=kaki!',\n",
    "                       config={ \"learning_rate\": lr,\n",
    "                                \"weight_decay\": weight_decay,\n",
    "                                \"patience\": 8,\n",
    "                                \"batch_size\": batch_size,\n",
    "                                \"epochs\": epochs,\n",
    "                                \"architecture\": VGG19,\n",
    "                                \"dataset\": \"Post_Impressionism\",\n",
    "                                }, name=f\"{VGG19}-best\")\n",
    "        ################\n",
    "train_model_with_hyperparams(model, train_loader, val_loader, optimizer, criterion, epochs=epochs, patience=8,device=device, trial=None, architecture=VGG19, fold=0, save_model=True, log=True)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "best_values = train.validation(model, criterion, test_loader, device)\n",
    "wandb.log(best_values)\n",
    "wandb.finish()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.19.1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>C:\\Projects\\deep_van_gogh\\wandb\\run-20250330_003949-rarosi9p</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/amitr5-tel-aviv-university/deep_van_gogh-best%3Dkaki%21/runs/rarosi9p' target=\"_blank\">VGG19-best</a></strong> to <a href='https://wandb.ai/amitr5-tel-aviv-university/deep_van_gogh-best%3Dkaki%21' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/amitr5-tel-aviv-university/deep_van_gogh-best%3Dkaki%21' target=\"_blank\">https://wandb.ai/amitr5-tel-aviv-university/deep_van_gogh-best%3Dkaki%21</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/amitr5-tel-aviv-university/deep_van_gogh-best%3Dkaki%21/runs/rarosi9p' target=\"_blank\">https://wandb.ai/amitr5-tel-aviv-university/deep_van_gogh-best%3Dkaki%21/runs/rarosi9p</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "execution_count": 44
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vIb8Ud6FiGuu"
   },
   "source": [
    "# Fine tuning AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "gaSN21pPiGdy",
    "outputId": "8101799f-ef2c-4ada-8a3d-7dc594b2385e",
    "ExecuteTime": {
     "end_time": "2025-03-29T21:12:42.969637Z",
     "start_time": "2025-03-29T21:12:41.990462Z"
    }
   },
   "source": [
    "# Load the AlexNet model \n",
    "alexnet = models.alexnet(weights=models.AlexNet_Weights.DEFAULT).to(device)\n",
    "# alexnet_model = FinedTunedModel(alexnet, ALEXNET).to(device)\n",
    "# alexnet_model"
   ],
   "outputs": [],
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "study = optuna.create_study(study_name=ALEXNET, direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, ALEXNET, config={}), n_trials=n_trials)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-29T21:38:02.171436Z",
     "start_time": "2025-03-29T21:37:35.549285Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Training the model - ALEXNET\n",
    "base_model = alexnet\n",
    "model = FinedTunedModel(base_model.to(device), ALEXNET).to(device)\n",
    "weight_decay=0.0000961196621799138\n",
    "lr=0.0000607994047379646\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0000607994047379646, weight_decay=0.0000961196621799138)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "batch_size=128\n",
    "epochs=5\n",
    "wandb.init(project='deep_van_gogh-best=kaki!',\n",
    "                       config={ \"learning_rate\": lr,\n",
    "                                \"weight_decay\": weight_decay,\n",
    "                                \"patience\": 8,\n",
    "                                \"batch_size\": batch_size,\n",
    "                                \"epochs\": epochs,\n",
    "                                \"architecture\": ALEXNET,\n",
    "                                \"dataset\": \"Post_Impressionism\",\n",
    "                                }, name=f\"{ALEXNET}-best\")\n",
    "        ################\n",
    "train_model_with_hyperparams(model, train_loader, val_loader, optimizer, criterion, epochs=epochs, patience=8,device=device, trial=None, architecture=ALEXNET, fold=0, save_model=True, log=True)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "best_values = train.validation(model, criterion, test_loader, device)\n",
    "wandb.log(best_values)\n",
    "wandb.finish()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.19.1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>C:\\Projects\\deep_van_gogh\\wandb\\run-20250330_003735-ueq17cxi</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/amitr5-tel-aviv-university/deep_van_gogh-best%3Dkaki%21/runs/ueq17cxi' target=\"_blank\">AlexNet-best</a></strong> to <a href='https://wandb.ai/amitr5-tel-aviv-university/deep_van_gogh-best%3Dkaki%21' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/amitr5-tel-aviv-university/deep_van_gogh-best%3Dkaki%21' target=\"_blank\">https://wandb.ai/amitr5-tel-aviv-university/deep_van_gogh-best%3Dkaki%21</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/amitr5-tel-aviv-university/deep_van_gogh-best%3Dkaki%21/runs/ueq17cxi' target=\"_blank\">https://wandb.ai/amitr5-tel-aviv-university/deep_van_gogh-best%3Dkaki%21/runs/ueq17cxi</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▃▅▆█</td></tr><tr><td>Train Accuracy</td><td>▁▇███</td></tr><tr><td>Train Loss</td><td>█▂▁▁▁</td></tr><tr><td>Validation AUC</td><td>▇████▁</td></tr><tr><td>Validation Accuracy</td><td>▇█▇▇▇▁</td></tr><tr><td>Validation F1</td><td>▇█▇▇▇▁</td></tr><tr><td>Validation Loss</td><td>▁▁▁▁▂█</td></tr><tr><td>Validation Precision</td><td>▆█▇▇▇▁</td></tr><tr><td>Validation Recall</td><td>▇█▇▇▇▁</td></tr><tr><td>Validation Specificity</td><td>▁▄▁▄▁█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>5</td></tr><tr><td>Train Accuracy</td><td>0.99795</td></tr><tr><td>Train Loss</td><td>0.00664</td></tr><tr><td>Validation AUC</td><td>0.92874</td></tr><tr><td>Validation Accuracy</td><td>0.91848</td></tr><tr><td>Validation F1</td><td>0.91201</td></tr><tr><td>Validation Loss</td><td>0.53906</td></tr><tr><td>Validation Precision</td><td>0.92364</td></tr><tr><td>Validation Recall</td><td>0.91848</td></tr><tr><td>Validation Specificity</td><td>0.99577</td></tr></table><br/></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">AlexNet-best</strong> at: <a href='https://wandb.ai/amitr5-tel-aviv-university/deep_van_gogh-best%3Dkaki%21/runs/ueq17cxi' target=\"_blank\">https://wandb.ai/amitr5-tel-aviv-university/deep_van_gogh-best%3Dkaki%21/runs/ueq17cxi</a><br> View project at: <a href='https://wandb.ai/amitr5-tel-aviv-university/deep_van_gogh-best%3Dkaki%21' target=\"_blank\">https://wandb.ai/amitr5-tel-aviv-university/deep_van_gogh-best%3Dkaki%21</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250330_003735-ueq17cxi\\logs</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 43
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "analysing results"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-29T21:33:08.605919Z",
     "start_time": "2025-03-29T21:33:05.614174Z"
    }
   },
   "source": "",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▂▂▃▄▁▂▂▃▄▅▅▆▇▇█▁▂▂▁▂▁▂▂</td></tr><tr><td>Train Accuracy</td><td>█████▇██████████▄██▁▅▂▆▇</td></tr><tr><td>Train Loss</td><td>▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▅▁▁█▄▇▃▂</td></tr><tr><td>Validation AUC</td><td>▄▄▃▃▃▃▃▃▂▃▃▂▂▂▁▂▂▂▂▁▇▅██</td></tr><tr><td>Validation Accuracy</td><td>▇▆▇▆▆▇▆▇▇▇▆█▇▆▅▅▅▅▄▁▃▂▇▅</td></tr><tr><td>Validation F1</td><td>█▇▇▇▇▇▇▇▇▇▆█▇▆▅▆▆▆▅▁▃▂█▆</td></tr><tr><td>Validation Loss</td><td>▇▇▇▇▇▇▆▆▇▇▇▇▇▇█▇▆▆▆▁▁▁▁▁</td></tr><tr><td>Validation Precision</td><td>█▇▇▇▇▇▇▇▇▇▆█▇▆▅▆▆▆▅▁▃▂█▆</td></tr><tr><td>Validation Recall</td><td>▇▆▇▆▆▇▆▇▇▇▆█▇▆▅▅▅▅▄▁▃▂▇▅</td></tr><tr><td>Validation Specificity</td><td>▃▃▄▂▁▇▃▄▆▃██▅▅▆▃▅▂▁▇▆▇▅▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>3</td></tr><tr><td>Train Accuracy</td><td>0.98854</td></tr><tr><td>Train Loss</td><td>0.03451</td></tr><tr><td>Validation AUC</td><td>0.95483</td></tr><tr><td>Validation Accuracy</td><td>0.96306</td></tr><tr><td>Validation F1</td><td>0.9622</td></tr><tr><td>Validation Loss</td><td>0.11404</td></tr><tr><td>Validation Precision</td><td>0.96162</td></tr><tr><td>Validation Recall</td><td>0.96306</td></tr><tr><td>Validation Specificity</td><td>0.9838</td></tr></table><br/></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">AlexNet_trial_1</strong> at: <a href='https://wandb.ai/amitr5-tel-aviv-university/deep_van_gogh-112311/runs/huxf7klj' target=\"_blank\">https://wandb.ai/amitr5-tel-aviv-university/deep_van_gogh-112311/runs/huxf7klj</a><br> View project at: <a href='https://wandb.ai/amitr5-tel-aviv-university/deep_van_gogh-112311' target=\"_blank\">https://wandb.ai/amitr5-tel-aviv-university/deep_van_gogh-112311</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250329_223217-huxf7klj\\logs</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 41
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZMIPaYdChtVL"
   },
   "source": [
    "# Style transfer function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "gy8lmbPmhj9H",
    "outputId": "330638de-9f78-4d50-c423-bbab448afc37"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 196
    },
    "id": "2cMigqU0CGg5",
    "outputId": "afdc3a89-f2ad-457b-eeb7-b4aabcf214ca"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "2UNqmGA2DXDj",
    "outputId": "18e5c745-d27d-4f23-97cf-717b194bd3c3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-dC9MS7V6WZF",
    "outputId": "80757501-0728-4fe1-96b7-a15122faad92"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w93PNhRgHVue",
    "outputId": "704e1556-8d2f-4c90-af0e-bc26aa7a072e"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "24UKrxg-H25c"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "name": "python3",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
